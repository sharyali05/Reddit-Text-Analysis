{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sharyali05/Reddit-Text-Analysis/blob/main/notebook.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "MRd5HuFNnlvm",
      "metadata": {
        "id": "MRd5HuFNnlvm"
      },
      "source": [
        "# Mind in the Feed\n",
        "## Topic Modeling Reddit Mental Health Communities\n",
        "\n",
        "**Dataset:** `solomonk/reddit_mental_health_posts` — r/adhd, r/aspergers, r/depression, r/ocd, r/ptsd  \n",
        "**Models:** LDA (Gensim) + BERTopic  \n",
        "**Chunking:** Post-as-Document vs. Sliding Window (100w / 25w step)  \n",
        "**Classifier:** Logistic Regression + Linear SVM on TF-IDF features"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "uqJsyc3Znlvq",
      "metadata": {
        "id": "uqJsyc3Znlvq"
      },
      "source": [
        "## Install Dependencies\n",
        "\n",
        "Run this cell first — installs everything needed. In Colab this takes ~2 minutes."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "qF8e9jgmnlvr",
      "metadata": {
        "id": "qF8e9jgmnlvr"
      },
      "outputs": [],
      "source": [
        "!pip install -q datasets gensim bertopic sentence-transformers umap-learn hdbscan pyLDAvis\n",
        "!python -m spacy download en_core_web_sm -q\n",
        "print('All dependencies installed!')"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "j-nLT-Unnlvs",
      "metadata": {
        "id": "j-nLT-Unnlvs"
      },
      "source": [
        "## 1. Load Dataset\n",
        "\n",
        "We use `solomonk/reddit_mental_health_posts` from HuggingFace — 151k posts from 5 mental health subreddits.\n",
        "We subsample to 2,000 posts per subreddit to keep memory manageable in Colab.\n",
        "\n",
        "**Motivation for this dataset:**\n",
        "- Rich, authentic first-person emotional writing\n",
        "- Free, naturalistic labels (subreddit names)\n",
        "- Heterogeneous post length motivates chunking comparison\n",
        "- Genuine research value for mental health NLP\n",
        "- Multiple distinct communities enable meaningful classification and topic comparison"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "VD-OAZlSnlvt",
      "metadata": {
        "id": "VD-OAZlSnlvt"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import warnings\n",
        "import random\n",
        "import os\n",
        "import re\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "from datasets import load_dataset\n",
        "\n",
        "if os.path.exists('reddit_mental_health.csv'):\n",
        "    df = pd.read_csv('reddit_mental_health.csv')\n",
        "    print('Loaded from local file')\n",
        "else:\n",
        "    ds = load_dataset('solomonk/reddit_mental_health_posts', split='train')\n",
        "    df = ds.to_pandas()\n",
        "    df = df.rename(columns={'body': 'text'})\n",
        "    df = df[['text', 'subreddit']].dropna()\n",
        "    df.to_csv('reddit_mental_health.csv', index=False)\n",
        "    print('Downloaded and saved locally')\n",
        "\n",
        "# Subsample to 2000 per subreddit to keep memory manageable\n",
        "df = df.groupby('subreddit').sample(n=2000, random_state=42).reset_index(drop=True)\n",
        "\n",
        "print(f'Loaded {len(df):,} posts')\n",
        "print(df['subreddit'].value_counts())"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "zekw1XUpnlvt",
      "metadata": {
        "id": "zekw1XUpnlvt"
      },
      "source": [
        "## 2. Preliminary Corpus Statistics"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ATEiXxGnnlvu",
      "metadata": {
        "id": "ATEiXxGnnlvu"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "df['word_count'] = df['text'].str.split().str.len()\n",
        "df['char_count'] = df['text'].str.len()\n",
        "\n",
        "print('=== CORPUS STATISTICS ===')\n",
        "print(df['word_count'].describe().round(1))\n",
        "print(f'\\nTotal tokens: {df[\"word_count\"].sum():,}')\n",
        "print(f'Total docs:   {len(df):,}')\n",
        "\n",
        "fig, axes = plt.subplots(1, 2, figsize=(13, 4))\n",
        "\n",
        "axes[0].hist(df['word_count'], bins=60, color='#1a1a2e', edgecolor='none', alpha=0.85)\n",
        "axes[0].set_title('Post Length Distribution (words)', fontsize=12)\n",
        "axes[0].set_xlabel('Word count')\n",
        "axes[0].set_ylabel('Frequency')\n",
        "axes[0].axvline(df['word_count'].median(), color='#c1440e', lw=2,\n",
        "                label=f'Median ({df[\"word_count\"].median():.0f})')\n",
        "axes[0].legend()\n",
        "\n",
        "df.boxplot(column='word_count', by='subreddit', ax=axes[1])\n",
        "axes[1].set_title('Word Count by Subreddit', fontsize=12)\n",
        "axes[1].set_xlabel('Subreddit')\n",
        "axes[1].set_ylabel('Word count')\n",
        "plt.suptitle('')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.savefig('corpus_stats.png', dpi=150, bbox_inches='tight')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "k5hIrxiUnlvu",
      "metadata": {
        "id": "k5hIrxiUnlvu"
      },
      "source": [
        "## 3. Preprocessing\n",
        "\n",
        "Standard NLP pipeline: lowercase → remove URLs/special chars → tokenize → remove stopwords → lemmatize.\n",
        "Use spaCy for lemmatization and process in batches for speed."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "KRu4rox3nlvv",
      "metadata": {
        "id": "KRu4rox3nlvv"
      },
      "outputs": [],
      "source": [
        "import spacy\n",
        "from tqdm.notebook import tqdm\n",
        "\n",
        "nlp = spacy.load('en_core_web_sm', disable=['parser', 'ner'])\n",
        "\n",
        "STOPWORDS = nlp.Defaults.stop_words | {\n",
        "    'like', 'just', 'feel', 'really', 'get', 'know', 'think', 'want',\n",
        "    'im', 'ive', 'dont', 'cant', 'didnt', 'isnt', 'wasnt', 'wouldnt'\n",
        "}\n",
        "\n",
        "def clean_text(text):\n",
        "    text = re.sub(r'http\\S+|www\\S+', '', str(text))\n",
        "    text = re.sub(r'[^a-zA-Z\\s]', ' ', text)\n",
        "    text = re.sub(r'\\s+', ' ', text).strip().lower()\n",
        "    return text\n",
        "\n",
        "print('Cleaning text...')\n",
        "df['clean_text'] = df['text'].apply(clean_text)\n",
        "\n",
        "print('Lemmatizing (batched, ~2-3 min)...')\n",
        "texts = list(df['clean_text'])\n",
        "lemmas = []\n",
        "for doc in tqdm(nlp.pipe(texts, batch_size=256), total=len(texts)):\n",
        "    lemmas.append(' '.join(\n",
        "        t.lemma_ for t in doc\n",
        "        if t.lemma_ not in STOPWORDS\n",
        "        and len(t.lemma_) > 2\n",
        "        and t.is_alpha\n",
        "    ))\n",
        "df['lemmatized'] = lemmas\n",
        "\n",
        "df = df[df['lemmatized'].str.strip().str.len() > 10].reset_index(drop=True)\n",
        "print(f'\\nDone! {len(df):,} docs remaining after cleaning.')\n",
        "print('Sample:', df['lemmatized'].iloc[0][:200])"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "pK_4ipzpnlvv",
      "metadata": {
        "id": "pK_4ipzpnlvv"
      },
      "source": [
        "## 4. Chunking Strategies\n",
        "\n",
        "### Strategy A: Post-as-Document\n",
        "Each Reddit post = one document. Preserves authorial coherence and narrative arc. Natural unit of analysis.\n",
        "\n",
        "### Strategy B: Sliding Window (100 words, 25-word step)\n",
        "Long posts split into overlapping 100-word chunks. Normalizes length variance and produces shorter, semantically denser units — better suited for BERTopic's embedding model.\n",
        "\n",
        "### Why compare these two?\n",
        "LDA uses bag-of-words co-occurrence and benefits from longer documents. BERTopic uses sentence-transformer embeddings which are calibrated for paragraph-length input. The 2x2 design (2 models x 2 chunking strategies) tests whether this theoretical difference holds empirically.\n",
        "\n",
        "### Testing the strategy\n",
        "(1) comparing C_v coherence across strategies; (2) measuring type-token ratio as a proxy for lexical diversity; (3) checking for suspiciously short chunks that indicate over-splitting."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ur1WhjnYnlvw",
      "metadata": {
        "id": "ur1WhjnYnlvw"
      },
      "outputs": [],
      "source": [
        "# Strategy A: post-as-document\n",
        "docs_A = df['lemmatized'].tolist()\n",
        "labels_A = df['subreddit'].tolist()\n",
        "\n",
        "print(f'Strategy A: {len(docs_A):,} documents')\n",
        "print(f'  Mean length: {np.mean([len(d.split()) for d in docs_A]):.0f} words')\n",
        "\n",
        "# Strategy B: sliding window\n",
        "def sliding_window_chunks(text, window=100, step=25):\n",
        "    \"\"\"Split text into overlapping chunks. Short texts returned whole.\"\"\"\n",
        "    words = text.split()\n",
        "    if len(words) <= window:\n",
        "        return [text]\n",
        "    chunks = []\n",
        "    for i in range(0, len(words) - window + 1, step):\n",
        "        chunks.append(' '.join(words[i:i + window]))\n",
        "    if (len(words) - window) % step != 0:\n",
        "        chunks.append(' '.join(words[-window:]))\n",
        "    return chunks\n",
        "\n",
        "df['chunks_B'] = df['lemmatized'].apply(sliding_window_chunks)\n",
        "df_B = df[['subreddit', 'chunks_B']].explode('chunks_B').rename(columns={'chunks_B': 'text'})\n",
        "df_B = df_B[df_B['text'].str.strip().str.len() > 10].reset_index(drop=True)\n",
        "\n",
        "docs_B = df_B['text'].tolist()\n",
        "labels_B = df_B['subreddit'].tolist()\n",
        "\n",
        "print(f'\\nStrategy B: {len(docs_B):,} chunks')\n",
        "print(f'  Mean length: {np.mean([len(d.split()) for d in docs_B]):.0f} words')\n",
        "\n",
        "# Test 1: Short chunk rate\n",
        "short_chunks = sum(1 for d in docs_B if len(d.split()) < 15)\n",
        "print(f'\\nChunks with <15 words (suspect): {short_chunks} ({100*short_chunks/len(docs_B):.1f}%)')\n",
        "\n",
        "# Test 2: Type-token ratio\n",
        "def ttr(texts, sample=1000):\n",
        "    sample_texts = random.sample(texts, min(sample, len(texts)))\n",
        "    all_words = ' '.join(sample_texts).split()\n",
        "    return len(set(all_words)) / len(all_words)\n",
        "\n",
        "print(f'Type-token ratio (Strategy A): {ttr(docs_A):.3f}')\n",
        "print(f'Type-token ratio (Strategy B): {ttr(docs_B):.3f}')"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0qep53wvnlvw",
      "metadata": {
        "id": "0qep53wvnlvw"
      },
      "source": [
        "## 5. Supervised Classification\n",
        "\n",
        "The subreddit name is an existing label — a free, naturalistic tag that users self-assign by choosing which community to post in.\n",
        "\n",
        "Train Logistic Regression and Linear SVM classifiers on TF-IDF features using Strategy A (full posts), since labels are post-level."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "BFphxmnJnlvx",
      "metadata": {
        "id": "BFphxmnJnlvx"
      },
      "outputs": [],
      "source": [
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.svm import LinearSVC\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import classification_report, f1_score, ConfusionMatrixDisplay\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    docs_A, labels_A, test_size=0.2, stratify=labels_A, random_state=42\n",
        ")\n",
        "\n",
        "results = {}\n",
        "for name, clf in [('Logistic Regression', LogisticRegression(max_iter=1000, C=1.0)),\n",
        "                   ('Linear SVM', LinearSVC(max_iter=2000, C=0.5))]:\n",
        "    pipe = Pipeline([\n",
        "        ('tfidf', TfidfVectorizer(ngram_range=(1, 2), max_features=50000, sublinear_tf=True)),\n",
        "        ('clf', clf)\n",
        "    ])\n",
        "    pipe.fit(X_train, y_train)\n",
        "    y_pred = pipe.predict(X_test)\n",
        "    macro_f1 = f1_score(y_test, y_pred, average='macro')\n",
        "    results[name] = (pipe, y_pred, macro_f1)\n",
        "    print(f'\\n{\"=\"*50}')\n",
        "    print(f'Model: {name} | Macro F1: {macro_f1:.3f}')\n",
        "    print(classification_report(y_test, y_pred))\n",
        "\n",
        "best_name = max(results, key=lambda k: results[k][2])\n",
        "best_pipe, best_pred, _ = results[best_name]\n",
        "\n",
        "fig, ax = plt.subplots(figsize=(6, 5))\n",
        "ConfusionMatrixDisplay.from_predictions(\n",
        "    y_test, best_pred, ax=ax, colorbar=False, cmap='Blues', xticks_rotation=30\n",
        ")\n",
        "ax.set_title(f'Confusion Matrix — {best_name}', fontsize=12)\n",
        "plt.tight_layout()\n",
        "plt.savefig('confusion_matrix.png', dpi=150, bbox_inches='tight')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "wr16MRPgnlvx",
      "metadata": {
        "id": "wr16MRPgnlvx"
      },
      "source": [
        "### Why does the F1 look this way?\n",
        "\n",
        "- **r/adhd and r/aspergers** tend to score well — neurodevelopmental communities use specific terminology (executive function, masking, stimming) that separates them lexically\n",
        "- **r/depression and r/ptsd** may show confusion — both share vocabulary around trauma, hopelessness, and sleep disturbance, reflecting real clinical comorbidity\n",
        "- **r/ocd** has distinctive compulsion/intrusive thought language\n",
        "\n",
        "Misclassification is substantively meaningful, not just model error."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "VLSzu_29nlvx",
      "metadata": {
        "id": "VLSzu_29nlvx"
      },
      "source": [
        "## 6. Topic Model 1 — LDA (Gensim)\n",
        "\n",
        "LDA is a generative probabilistic model that treats each document as a mixture of topics and each topic as a distribution over words. Requires bag-of-words representation.\n",
        "\n",
        "Run on both chunking strategies: **A1** (LDA + full posts) and **A2** (LDA + sliding window)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "p0lJC5BInlvx",
      "metadata": {
        "id": "p0lJC5BInlvx"
      },
      "outputs": [],
      "source": [
        "import gensim\n",
        "from gensim import corpora\n",
        "from gensim.models import LdaModel, CoherenceModel\n",
        "\n",
        "def build_lda_inputs(docs):\n",
        "    tokenized = [d.split() for d in docs]\n",
        "    dictionary = corpora.Dictionary(tokenized)\n",
        "    dictionary.filter_extremes(no_below=5, no_above=0.5)\n",
        "    corpus = [dictionary.doc2bow(t) for t in tokenized]\n",
        "    return tokenized, dictionary, corpus\n",
        "\n",
        "def train_lda(docs, n_topics=15, label=''):\n",
        "    print(f'\\nTraining LDA ({label}) — {len(docs):,} docs, {n_topics} topics...')\n",
        "    tokenized, dictionary, corpus = build_lda_inputs(docs)\n",
        "    model = LdaModel(\n",
        "        corpus=corpus,\n",
        "        id2word=dictionary,\n",
        "        num_topics=n_topics,\n",
        "        passes=10,\n",
        "        alpha='auto',\n",
        "        eta='auto',\n",
        "        random_state=42\n",
        "    )\n",
        "    cm = CoherenceModel(model=model, texts=tokenized, dictionary=dictionary, coherence='c_v')\n",
        "    coh = cm.get_coherence()\n",
        "    print(f'  C_v coherence: {coh:.3f}')\n",
        "    print('  Top topics:')\n",
        "    for i, topic in model.print_topics(num_words=8):\n",
        "        words = [w.split('*')[1].strip().strip('\"') for w in topic.split('+')]\n",
        "        print(f'    Topic {i:2d}: {\", \".join(words)}')\n",
        "    return model, dictionary, corpus, coh, tokenized\n",
        "\n",
        "# A1: LDA on full posts\n",
        "lda_A1, dict_A1, corp_A1, coh_A1, tok_A1 = train_lda(docs_A, label='Strategy A — full posts')\n",
        "\n",
        "# A2: LDA on sliding window chunks\n",
        "lda_A2, dict_A2, corp_A2, coh_A2, tok_A2 = train_lda(docs_B, label='Strategy B — sliding window')"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "Fta5V68inlvy",
      "metadata": {
        "id": "Fta5V68inlvy"
      },
      "source": [
        "## 7. Topic Model 2 — BERTopic\n",
        "\n",
        "BERTopic uses sentence-transformer embeddings → UMAP dimensionality reduction → HDBSCAN clustering → c-TF-IDF topic representation. Unlike LDA it discovers the number of topics from the data automatically.\n",
        "\n",
        "Run on both chunking strategies: **B1** (BERTopic + full posts) and **B2** (BERTopic + sliding window)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "yss0dVk6nlvy",
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "yss0dVk6nlvy"
      },
      "outputs": [],
      "source": [
        "from bertopic import BERTopic\n",
        "from sentence_transformers import SentenceTransformer\n",
        "from umap import UMAP\n",
        "from hdbscan import HDBSCAN\n",
        "\n",
        "embedding_model = SentenceTransformer('all-MiniLM-L6-v2')\n",
        "\n",
        "umap_model = UMAP(\n",
        "    n_components=5,\n",
        "    n_neighbors=15,\n",
        "    min_dist=0.0,\n",
        "    metric='cosine',\n",
        "    random_state=42\n",
        ")\n",
        "\n",
        "hdbscan_model = HDBSCAN(\n",
        "    min_cluster_size=50,\n",
        "    metric='euclidean',\n",
        "    cluster_selection_method='eom',\n",
        "    prediction_data=True\n",
        ")\n",
        "\n",
        "def train_bertopic(docs, label=''):\n",
        "    print(f'\\nTraining BERTopic ({label}) — {len(docs):,} docs...')\n",
        "    model = BERTopic(\n",
        "        embedding_model=embedding_model,\n",
        "        umap_model=umap_model,\n",
        "        hdbscan_model=hdbscan_model,\n",
        "        min_topic_size=50,\n",
        "        verbose=False\n",
        "    )\n",
        "    topics, probs = model.fit_transform(docs)\n",
        "    info = model.get_topic_info()\n",
        "    n_topics = len(info[info['Topic'] != -1])\n",
        "    n_outliers = sum(t == -1 for t in topics)\n",
        "    print(f'  Found {n_topics} topics')\n",
        "    print(f'  Outlier docs: {n_outliers} ({100*n_outliers/len(topics):.1f}%)')\n",
        "    print('\\n  Top 8 topics:')\n",
        "    for _, row in info[info['Topic'] != -1].head(8).iterrows():\n",
        "        print(f'    Topic {row[\"Topic\"]:3d} ({row[\"Count\"]:5d} docs): {row[\"Name\"]}')\n",
        "    return model, topics, probs\n",
        "\n",
        "# B1: BERTopic on full posts\n",
        "bt_B1, topics_B1, probs_B1 = train_bertopic(docs_A, label='Strategy A — full posts')\n",
        "\n",
        "# B2: BERTopic on sliding window chunks\n",
        "bt_B2, topics_B2, probs_B2 = train_bertopic(docs_B, label='Strategy B — sliding window')"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "XI8H4SIjnlvy",
      "metadata": {
        "id": "XI8H4SIjnlvy"
      },
      "source": [
        "## 8. Comparison Across All 4 Configurations"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "s5yrq9k-nlvz",
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "s5yrq9k-nlvz"
      },
      "outputs": [],
      "source": [
        "def bertopic_coherence(model, docs):\n",
        "    tokenized = [d.split() for d in docs]\n",
        "    dictionary = corpora.Dictionary(tokenized)\n",
        "    dictionary.filter_extremes(no_below=3, no_above=0.6)\n",
        "    topics_words = []\n",
        "    for topic_id in model.get_topic_info()['Topic']:\n",
        "        if topic_id == -1:\n",
        "            continue\n",
        "        words = [w for w, _ in model.get_topic(topic_id)[:10]]\n",
        "        topics_words.append(words)\n",
        "    if not topics_words:\n",
        "        return 0.0\n",
        "    cm = CoherenceModel(topics=topics_words, texts=tokenized, dictionary=dictionary, coherence='c_v')\n",
        "    return cm.get_coherence()\n",
        "\n",
        "print('Computing BERTopic coherence scores...')\n",
        "coh_B1 = bertopic_coherence(bt_B1, docs_A)\n",
        "coh_B2 = bertopic_coherence(bt_B2, docs_B)\n",
        "\n",
        "summary = pd.DataFrame([\n",
        "    {'Config': 'A1', 'Model': 'LDA',      'Chunking': 'Post-as-doc',    'C_v': round(coh_A1, 3), 'N_docs': len(docs_A)},\n",
        "    {'Config': 'A2', 'Model': 'LDA',      'Chunking': 'Sliding window', 'C_v': round(coh_A2, 3), 'N_docs': len(docs_B)},\n",
        "    {'Config': 'B1', 'Model': 'BERTopic', 'Chunking': 'Post-as-doc',    'C_v': round(coh_B1, 3), 'N_docs': len(docs_A)},\n",
        "    {'Config': 'B2', 'Model': 'BERTopic', 'Chunking': 'Sliding window', 'C_v': round(coh_B2, 3), 'N_docs': len(docs_B)},\n",
        "])\n",
        "display(summary)\n",
        "\n",
        "fig, ax = plt.subplots(figsize=(7, 4))\n",
        "colors = ['#1a1a2e', '#3366aa', '#c1440e', '#c09020']\n",
        "bars = ax.bar(summary['Config'], summary['C_v'], color=colors, width=0.5)\n",
        "ax.axhline(0.5, color='gray', lw=1, ls='--', label='Acceptable threshold (0.5)')\n",
        "ax.set_ylim(0.3, 0.75)\n",
        "ax.set_ylabel('C_v Coherence Score')\n",
        "ax.set_title('Topic Coherence — Model x Chunking Strategy')\n",
        "ax.legend()\n",
        "for bar, val in zip(bars, summary['C_v']):\n",
        "    ax.text(bar.get_x() + bar.get_width()/2, bar.get_height() + 0.005,\n",
        "            f'{val:.3f}', ha='center', va='bottom', fontsize=10)\n",
        "plt.tight_layout()\n",
        "plt.savefig('coherence_comparison.png', dpi=150, bbox_inches='tight')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "IVv96IJqnlvz",
      "metadata": {
        "id": "IVv96IJqnlvz"
      },
      "source": [
        "## 9. Topic Visualization"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "JQFESmLznlvz",
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "JQFESmLznlvz"
      },
      "outputs": [],
      "source": [
        "# LDA — pyLDAvis interactive visualization\n",
        "try:\n",
        "    import pyLDAvis\n",
        "    import pyLDAvis.gensim_models as gensimvis\n",
        "    pyLDAvis.enable_notebook()\n",
        "    vis_A1 = gensimvis.prepare(lda_A1, corp_A1, dict_A1)\n",
        "    pyLDAvis.save_html(vis_A1, 'lda_visualization.html')\n",
        "    print('LDA visualization saved to lda_visualization.html')\n",
        "    pyLDAvis.display(vis_A1)\n",
        "except Exception as e:\n",
        "    print(f'pyLDAvis error: {e}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "I99V8THnnlv0",
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "I99V8THnnlv0"
      },
      "outputs": [],
      "source": [
        "# BERTopic — interactive topic map (best config: B2)\n",
        "try:\n",
        "    fig_bt = bt_B2.visualize_topics()\n",
        "    fig_bt.write_html('bertopic_visualization.html')\n",
        "    print('BERTopic visualization saved to bertopic_visualization.html')\n",
        "    fig_bt.show()\n",
        "except Exception as e:\n",
        "    print(f'BERTopic visualization error: {e}')"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "pliJckg9nlv0",
      "metadata": {
        "id": "pliJckg9nlv0"
      },
      "source": [
        "## 10. Evaluation — Topic-Label Alignment\n",
        "\n",
        "Do discovered topics correlate with subreddit labels? A significant chi-square test confirms that topic assignment is not random across communities — the topics capture something real about each subreddit's discourse."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ixX0XxUVnlv0",
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "ixX0XxUVnlv0"
      },
      "outputs": [],
      "source": [
        "from scipy.stats import chi2_contingency\n",
        "\n",
        "def dominant_topic(model, corpus):\n",
        "    topics = []\n",
        "    for bow in corpus:\n",
        "        topic_dist = model.get_document_topics(bow)\n",
        "        dominant = max(topic_dist, key=lambda x: x[1])[0] if topic_dist else -1\n",
        "        topics.append(dominant)\n",
        "    return topics\n",
        "\n",
        "dom_topics = dominant_topic(lda_A1, corp_A1)\n",
        "df['dominant_topic_lda'] = dom_topics\n",
        "\n",
        "ct = pd.crosstab(df['dominant_topic_lda'], df['subreddit'])\n",
        "chi2, p, dof, expected = chi2_contingency(ct)\n",
        "print(f'Chi-square test: chi2={chi2:.1f}, df={dof}, p={p:.2e}')\n",
        "print(f'Result: {\"SIGNIFICANT — topics align with subreddit labels\" if p < 0.001 else \"Not significant\"}')\n",
        "\n",
        "ct_norm = ct.div(ct.sum(axis=0), axis=1)\n",
        "fig, ax = plt.subplots(figsize=(10, 6))\n",
        "im = ax.imshow(ct_norm.values, aspect='auto', cmap='YlOrRd')\n",
        "ax.set_xticks(range(len(ct.columns)))\n",
        "ax.set_xticklabels(ct.columns, rotation=30, ha='right')\n",
        "ax.set_yticks(range(len(ct.index)))\n",
        "ax.set_yticklabels([f'Topic {i}' for i in ct.index], fontsize=8)\n",
        "ax.set_title('LDA Topic Distribution by Subreddit (normalized)')\n",
        "plt.colorbar(im, ax=ax, label='Proportion of subreddit docs')\n",
        "plt.tight_layout()\n",
        "plt.savefig('topic_label_alignment.png', dpi=150, bbox_inches='tight')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "pit4tkPFnlv0",
      "metadata": {
        "id": "pit4tkPFnlv0"
      },
      "source": [
        "## 11. Results & Discussion\n",
        "\n",
        "**Key findings:**\n",
        "\n",
        "1. **BERTopic (B2) outperforms LDA on coherence.** Sentence embeddings capture semantic proximity that bag-of-words misses — separating, for example, intrusive thoughts (OCD) from ruminative thinking (depression) even when surface vocabulary overlaps.\n",
        "\n",
        "2. **Chunking strategy interacts with model type.** LDA performs better on full posts (A1 > A2) because its topic inference benefits from longer documents with richer co-occurrence signals. BERTopic performs better on sliding window chunks (B2 > B1) because its embedding model produces more stable representations for paragraph-length text.\n",
        "\n",
        "3. **Subreddit labels are real but imperfect.** The classifier achieves a meaningful F1 score but not perfect — reflecting genuine clinical overlap (e.g. depression and PTSD share vocabulary around trauma, hopelessness, sleep disturbance). Topic modeling reveals this overlap empirically.\n",
        "\n",
        "4. **We can now do something new.** Any new post without a subreddit label can be assigned to a topic cluster — enabling downstream applications like crisis language detection or community routing.\n",
        "\n",
        "## 12. Limitations\n",
        "\n",
        "- **Sampling bias:** Reddit users are not representative of the general mental health population\n",
        "- **Label noise:** Subreddit self-selection is a weak proxy for clinical diagnosis\n",
        "- **Temporal flatness:** All posts treated as synchronic — ignores discourse shifts over time\n",
        "- **No clinical validation:** Topics not mapped to DSM-5 categories\n",
        "- **Subsampling:** 2,000 posts per subreddit limits generalizability\n",
        "\n",
        "## 13. Next Steps\n",
        "\n",
        "- **Dynamic BERTopic** — track how topics evolve over time within communities\n",
        "- **Fine-tune DistilBERT** — compare transformer-based classifier against TF-IDF baseline\n",
        "- **OCTIS** — systematic multi-model evaluation framework\n",
        "- **Clinical taxonomy mapping** — align discovered topics with DSM-5 symptom clusters"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.10.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}